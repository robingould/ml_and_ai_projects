{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Spark DataFrame"
      ],
      "metadata": {
        "id": "7QUsI11TGyQY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import and Install"
      ],
      "metadata": {
        "id": "iDBaduv-G_99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeGI9QjJwpgL",
        "outputId": "92af1d67-b82e-45c8-b64a-02040f3e0330"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=54e5fdd1217d6bf493cb33a2151d1f18d157b202b695a3d71b61d3ec4095ef98\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3706qGAAwVbV"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "from pyspark.sql.functions import sum, desc, year, asc\n",
        "from pyspark.sql import functions as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the data"
      ],
      "metadata": {
        "id": "0AY98QiWJiqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGxwp0rTxku6",
        "outputId": "bad28ab5-62e7-438c-d0e1-f57d068d0381"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading the Data\n"
      ],
      "metadata": {
        "id": "m-O1th6eHEZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "payment_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(r'/content/gdrive/My Drive/models/rental/payment.csv')\n",
        "payment_df = payment_df.alias('payment_df')\n",
        "payment_df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQjkVud4wWU-",
        "outputId": "3ddf790b-efba-4098-d5e2-a71f6e76a85f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+--------+---------+------+-------------------+-------------------+\n",
            "|payment_id|customer_id|staff_id|rental_id|amount|       payment_date|        last_update|\n",
            "+----------+-----------+--------+---------+------+-------------------+-------------------+\n",
            "|         1|          1|       1|       76|  2.99|2005-05-25 11:30:37|2006-02-15 22:12:30|\n",
            "|         2|          1|       1|      573|  0.99|2005-05-28 10:35:23|2006-02-15 22:12:30|\n",
            "|         3|          1|       1|     1185|  5.99|2005-06-15 00:54:12|2006-02-15 22:12:30|\n",
            "+----------+-----------+--------+---------+------+-------------------+-------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rental_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(r'/content/gdrive/My Drive/models/rental/rental.csv')\n",
        "rental_df = rental_df.alias('rental_df')\n",
        "rental_df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XegbwI2-wWXn",
        "outputId": "fdbc4f2b-bc16-498a-8ea2-51e9823eb302"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------+------------+-----------+-------------------+--------+-------------------+\n",
            "|rental_id|        rental_date|inventory_id|customer_id|        return_date|staff_id|        last_update|\n",
            "+---------+-------------------+------------+-----------+-------------------+--------+-------------------+\n",
            "|        1|2005-05-24 22:53:30|         367|        130|2005-05-26 22:04:30|       1|2006-02-15 21:30:53|\n",
            "|        2|2005-05-24 22:54:33|        1525|        459|2005-05-28 19:40:33|       1|2006-02-15 21:30:53|\n",
            "|        3|2005-05-24 23:03:39|        1711|        408|2005-06-01 22:12:39|       1|2006-02-15 21:30:53|\n",
            "+---------+-------------------+------------+-----------+-------------------+--------+-------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "staff_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(r'/content/gdrive/My Drive/models/rental/staff.csv')\n",
        "staff_df = staff_df.alias('staff_df')\n",
        "staff_df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Me6vwdgwWcP",
        "outputId": "bfabc4f1-1b1d-4115-86df-8e970ddbdf66"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+---------+----------+-------+--------------------+--------+------+--------+--------------------+--------------+\n",
            "|staff_id|first_name|last_name|address_id|picture|               email|store_id|active|username|            password|   last_update|\n",
            "+--------+----------+---------+----------+-------+--------------------+--------+------+--------+--------------------+--------------+\n",
            "|       1|      Mike|  Hillyer|         3|   NULL|Mike.Hillyer@saki...|       1|     1|    Mike|8cb2237d0679ca88d...|2/15/2006 3:57|\n",
            "|       2|       Jon| Stephens|         4|   NULL|Jon.Stephens@saki...|       2|     1|     Jon|                NULL|2/15/2006 3:57|\n",
            "+--------+----------+---------+----------+-------+--------------------+--------+------+--------+--------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inventory_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(r'/content/gdrive/My Drive/models/rental/inventory.csv')\n",
        "inventory_df = inventory_df.alias('inventory_df')\n",
        "inventory_df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYObKaIuwWfn",
        "outputId": "b0e3e1d2-d5d0-4055-9756-fa95bd8d13c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------+--------+-------------------+\n",
            "|inventory_id|film_id|store_id|        last_update|\n",
            "+------------+-------+--------+-------------------+\n",
            "|           1|      1|       1|2006-02-15 05:09:17|\n",
            "|           2|      1|       1|2006-02-15 05:09:17|\n",
            "|           3|      1|       1|2006-02-15 05:09:17|\n",
            "+------------+-------+--------+-------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "store_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(r'/content/gdrive/My Drive/models/rental/store.csv')\n",
        "store_df = store_df.alias('store_df')\n",
        "store_df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVFoW5K9wWmZ",
        "outputId": "ab081e1f-42d5-4edf-c5be-5aed8c7c9ca0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------------+----------+-------------------+\n",
            "|store_id|manager_staff_id|address_id|        last_update|\n",
            "+--------+----------------+----------+-------------------+\n",
            "|       1|               1|         1|2006-02-15 04:57:12|\n",
            "|       2|               2|         2|2006-02-15 04:57:12|\n",
            "+--------+----------------+----------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "address_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(r'/content/gdrive/My Drive/models/rental/address.csv')\n",
        "address_df = address_df.alias('address_df')\n",
        "address_df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omdLe51pwWqD",
        "outputId": "9f20700b-39f2-48ab-9adf-8f0d1e8a2ffa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+--------+--------+-------+-----------+-----------+-------------------+\n",
            "|address_id|           address|address2|district|city_id|postal_code|      phone|        last_update|\n",
            "+----------+------------------+--------+--------+-------+-----------+-----------+-------------------+\n",
            "|         1| 47 MySakila Drive|    NULL| Alberta|    300|       NULL|       NULL|2014-09-25 22:30:27|\n",
            "|         2|28 MySQL Boulevard|    NULL|     QLD|    576|       NULL|       NULL|2014-09-25 22:30:09|\n",
            "|         3| 23 Workhaven Lane|    NULL| Alberta|    300|       NULL|14033335568|2014-09-25 22:30:27|\n",
            "+----------+------------------+--------+--------+-------+-----------+-----------+-------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(r'/content/gdrive/My Drive/models/rental/customer.csv')\n",
        "customer_df = customer_df.alias('customer_df')\n",
        "customer_df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgHn9GvdwWtv",
        "outputId": "2744e692-4562-4b20-b6c6-e8e98b181b33"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+----------+---------+--------------------+----------+------+-------------------+-------------------+\n",
            "|customer_id|store_id|first_name|last_name|               email|address_id|active|        create_date|        last_update|\n",
            "+-----------+--------+----------+---------+--------------------+----------+------+-------------------+-------------------+\n",
            "|          1|       1|      MARY|    SMITH|MARY.SMITH@sakila...|         5|     1|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
            "|          2|       1|  PATRICIA|  JOHNSON|PATRICIA.JOHNSON@...|         6|     1|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
            "|          3|       1|     LINDA| WILLIAMS|LINDA.WILLIAMS@sa...|         7|     1|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
            "+-----------+--------+----------+---------+--------------------+----------+------+-------------------+-------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "film_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(r'/content/gdrive/My Drive/models/rental/film.csv')\n",
        "film_df = film_df.alias('film_df')\n",
        "film_df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NIgEKFkyL10",
        "outputId": "3127058f-c777-4f7c-c42c-ae1d919a6e33"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------------+--------------------+------------+-----------+--------------------+---------------+-----------+------+----------------+------+--------------------+-------------------+\n",
            "|film_id|           title|         description|release_year|language_id|original_language_id|rental_duration|rental_rate|length|replacement_cost|rating|    special_features|        last_update|\n",
            "+-------+----------------+--------------------+------------+-----------+--------------------+---------------+-----------+------+----------------+------+--------------------+-------------------+\n",
            "|      1|ACADEMY DINOSAUR|A Epic Drama of a...|        2006|          1|                NULL|              6|       0.99|    86|           20.99|    PG|Deleted Scenes,Be...|2006-02-15 05:03:42|\n",
            "|      2|  ACE GOLDFINGER|A Astounding Epis...|        2006|          1|                NULL|              3|       4.99|    48|           12.99|     G|Trailers,Deleted ...|2006-02-15 05:03:42|\n",
            "|      3|ADAPTATION HOLES|A Astounding Refl...|        2006|          1|                NULL|              7|       2.99|    50|           18.99| NC-17|Trailers,Deleted ...|2006-02-15 05:03:42|\n",
            "+-------+----------------+--------------------+------------+-----------+--------------------+---------------+-----------+------+----------------+------+--------------------+-------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1"
      ],
      "metadata": {
        "id": "IbkfiLlwHIMB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a DataFrame based on the payment DataFrame. It contains a\n",
        "list of customer_id and total payment amount grouped by customer_id, sorted\n",
        "by the total amount in descending order. Other columns may be included as\n",
        "needed."
      ],
      "metadata": {
        "id": "uUlfxxyjHLlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, group the payment DataFrame by customer_id and calculate the sum of payment amount for each customer.\n",
        "# Then, order the DataFrame by the total payment amount in descending order.\n",
        "customer_payment_df = payment_df.groupBy(\"customer_id\").agg(sum(\"amount\").alias(\"total_payment\")) \\\n",
        "    .orderBy(\"total_payment\", ascending=False)\n",
        "\n",
        "# Show top 3 rows for verification purposes\n",
        "customer_payment_df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNPMfT4JFD4l",
        "outputId": "93883a78-f241-415a-c154-1623f097e9cf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+\n",
            "|customer_id|     total_payment|\n",
            "+-----------+------------------+\n",
            "|        526| 221.5500000000001|\n",
            "|        148| 216.5400000000001|\n",
            "|        144|195.58000000000007|\n",
            "+-----------+------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2"
      ],
      "metadata": {
        "id": "iMVfpb9tHOYS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a DataFrame based on the rental DataFrame. It contains a list\n",
        "of rentals from the rental DataFrame that were rented in 2005 ordered on\n",
        "return_date in ascending order. Other columns may be included as needed."
      ],
      "metadata": {
        "id": "MOAQYEwXHOln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, filter the rental DataFrame to include only rentals from 2005.\n",
        "# Finally, order the DataFrame by return_date in ascending order.\n",
        "rentals_2005_df = rental_df.filter(year(\"rental_date\") == 2005) \\\n",
        "    .orderBy(\"return_date\")\n",
        "\n",
        "# Show top 3 rows for verification purposes\n",
        "rentals_2005_df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9uQou_3FECf",
        "outputId": "0cbcc4c5-57f1-4c42-a40a-b0fbbd5b3a37"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------+------------+-----------+-------------------+--------+-------------------+\n",
            "|rental_id|        rental_date|inventory_id|customer_id|        return_date|staff_id|        last_update|\n",
            "+---------+-------------------+------------+-----------+-------------------+--------+-------------------+\n",
            "|       32|2005-05-25 04:06:21|        3832|        230|2005-05-25 23:55:21|       1|2006-02-15 21:30:53|\n",
            "|       21|2005-05-25 01:59:46|         146|        388|2005-05-26 01:01:46|       2|2006-02-15 21:30:53|\n",
            "|       14|2005-05-25 00:31:15|        2701|        446|2005-05-26 02:56:15|       1|2006-02-15 21:30:53|\n",
            "+---------+-------------------+------------+-----------+-------------------+--------+-------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3"
      ],
      "metadata": {
        "id": "MFuSuMk4HUw8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a DataFrame based on rental DataFrame . It contains a list of\n",
        "rental_id count from rental DataFrame grouped by staff_id."
      ],
      "metadata": {
        "id": "VizVWyoPHUzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, group the rental DataFrame by staff_id and count the number of rentals for each staff.\n",
        "rental_count_by_staff_df = rental_df.groupBy(\"staff_id\").count()\n",
        "\n",
        "# Show top 3 rows for verification purposes\n",
        "rental_count_by_staff_df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_GkPmSqFEIz",
        "outputId": "e4b6319c-2551-43af-c4e6-20aaf8913b8c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|staff_id|count|\n",
            "+--------+-----+\n",
            "|       1| 8040|\n",
            "|       2| 8004|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4"
      ],
      "metadata": {
        "id": "N_t4ChzCHbML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now add staff first and last name."
      ],
      "metadata": {
        "id": "PjzFD4AXHc-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, select the columns 'staff_id', 'first_name', and 'last_name' from the staff DataFrame.\n",
        "# Then, join the rental count DataFrame with the staff DataFrame on 'staff_id'.\n",
        "rental_count_with_staff_name_df = rental_count_by_staff_df.join(staff_df, \"staff_id\") \\\n",
        "    .select(\"staff_id\", \"first_name\", \"last_name\", \"count\")\n",
        "\n",
        "# Show top 3 rows for verification purposes\n",
        "rental_count_with_staff_name_df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09rNBhduFEPW",
        "outputId": "560280e6-1777-492b-f93e-89d0221e5939"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+---------+-----+\n",
            "|staff_id|first_name|last_name|count|\n",
            "+--------+----------+---------+-----+\n",
            "|       1|      Mike|  Hillyer| 8040|\n",
            "|       2|       Jon| Stephens| 8004|\n",
            "+--------+----------+---------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5"
      ],
      "metadata": {
        "id": "ogBGzsmGHhw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a DataFrame based on rental DataFrame, joined with\n",
        "inventory, store, and address DataFrames to get store address, joined with\n",
        "customer DataFrame to get customer first and last name, joined with staff\n",
        "DataFrame to get staff first and last name, joined with film data set to get film\n",
        "name and description, and ordered by return_date in the ascending order."
      ],
      "metadata": {
        "id": "VOixmdXaHh15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, join the rental DataFrame with inventory, store, address, customer, staff, and film DataFrames.\n",
        "# Finally, order the DataFrame by return_date in ascending order.\n",
        "rental_full_info_df = rental_df.join(inventory_df, \"inventory_id\") \\\n",
        "    .join(store_df, \"store_id\") \\\n",
        "    .join(address_df, \"address_id\") \\\n",
        "    .join(customer_df, \"customer_id\") \\\n",
        "    .join(staff_df, \"staff_id\") \\\n",
        "    .join(film_df, \"film_id\") \\\n",
        "    .select(\n",
        "        rental_df[\"rental_date\"].alias(\"rental_date\"),\n",
        "        rental_df[\"return_date\"].alias(\"return_date\"),\n",
        "        address_df[\"address\"].alias(\"store_address\"),\n",
        "        film_df[\"title\"].alias(\"film_title\"),\n",
        "        film_df[\"description\"].alias(\"film_description\"),\n",
        "        customer_df[\"first_name\"].alias(\"customer_first_name\"),\n",
        "        customer_df[\"last_name\"].alias(\"customer_last_name\"),\n",
        "        staff_df[\"first_name\"].alias(\"staff_first_name\"),\n",
        "        staff_df[\"last_name\"].alias(\"staff_last_name\")\n",
        "    ) \\\n",
        "    .orderBy(asc(\"return_date\"))\n",
        "\n",
        "# Show top 3 rows for verification purposes\n",
        "rental_full_info_df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2clm9kuFEVq",
        "outputId": "c8099bf5-af52-4315-a376-ac2164f21acb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------------------+------------------+------------------+--------------------+-------------------+------------------+----------------+---------------+\n",
            "|        rental_date|        return_date|     store_address|        film_title|    film_description|customer_first_name|customer_last_name|staff_first_name|staff_last_name|\n",
            "+-------------------+-------------------+------------------+------------------+--------------------+-------------------+------------------+----------------+---------------+\n",
            "|2005-05-25 04:06:21|2005-05-25 23:55:21|28 MySQL Boulevard| STALLION SUNDANCE|A Fast-Paced Tale...|                JOY|            GEORGE|            Mike|        Hillyer|\n",
            "|2005-05-25 01:59:46|2005-05-26 01:01:46| 47 MySakila Drive|     APACHE DIVINE|A Awe-Inspiring R...|              CRAIG|           MORRELL|             Jon|       Stephens|\n",
            "|2005-05-25 00:31:15|2005-05-26 02:56:15|28 MySQL Boulevard|MONTEREY LABYRINTH|A Awe-Inspiring D...|           THEODORE|              CULP|            Mike|        Hillyer|\n",
            "+-------------------+-------------------+------------------+------------------+--------------------+-------------------+------------------+----------------+---------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 6"
      ],
      "metadata": {
        "id": "8lkKO1MfHntR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a DataFrame that contains a list of customer_id whose sum\n",
        "amount of payment in 2005 is more than $200."
      ],
      "metadata": {
        "id": "mKGp-yDZHnv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, filter the payment DataFrame to include only payments from 2005.\n",
        "# Then, group the DataFrame by customer_id and calculate the sum of payment amount for each customer.\n",
        "# Finally, filter out customers whose total payment amount is more than $200.\n",
        "customer_payment_2005_df = payment_df.filter(year(\"payment_date\") == 2005) \\\n",
        "    .groupBy(\"customer_id\").agg(sum(\"amount\").alias(\"total_payment_2005\"))\n",
        "\n",
        "customers_over_200_df = customer_payment_2005_df.filter(\"total_payment_2005 > 200\")\n",
        "\n",
        "# Show top 3 rows for verification purposes\n",
        "customers_over_200_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDKEU5RlFEbp",
        "outputId": "5d38ae0f-1f9e-41db-c350-ce2c30d6203e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+\n",
            "|customer_id|total_payment_2005|\n",
            "+-----------+------------------+\n",
            "|        526| 221.5500000000001|\n",
            "|        148| 216.5400000000001|\n",
            "+-----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 7"
      ],
      "metadata": {
        "id": "z0KcaTlhHtBF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Join the result with customer DataFrame set to get their names."
      ],
      "metadata": {
        "id": "pFGBHvJsHtDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, join the DataFrame obtained in Task 6 with the customer DataFrame on 'customer_id'.\n",
        "customers_over_200_with_names_df = customers_over_200_df.join(customer_df, \"customer_id\") \\\n",
        "    .select(\"customer_id\", \"first_name\", \"last_name\", \"total_payment_2005\")\n",
        "\n",
        "# Show top 3 rows for verification purposes\n",
        "customers_over_200_with_names_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Xb-EmmyFEiU",
        "outputId": "0e455386-301d-4c69-b2ff-3850227341b1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+---------+------------------+\n",
            "|customer_id|first_name|last_name|total_payment_2005|\n",
            "+-----------+----------+---------+------------------+\n",
            "|        526|      KARL|     SEAL| 221.5500000000001|\n",
            "|        148|   ELEANOR|     HUNT| 216.5400000000001|\n",
            "+-----------+----------+---------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 8"
      ],
      "metadata": {
        "id": "mwVyDpioHyAT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a DataFrame that contains a list of customer_id that rented\n",
        "in 2005; Create another DataFrame that contains a list of customer_id that\n",
        "rented in 2006 (filter using rental_date).\n",
        "\n",
        "a. (1 point) Now create a DataFrame of customer_id that exist in the 2005\n",
        "DataFrame but not in the 2006 DataFrame . The count should be 441.\n",
        "\n",
        "b. (1 point) Now create a DataFrame of customer_id that exist in the 2006\n",
        "DataFrame but not in the 2005 DataFrame . The count should be 0."
      ],
      "metadata": {
        "id": "AvnQYBiFH0zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, filter the rental DataFrame to include only rentals from 2005 and 2006.\n",
        "# Then, select distinct customer_ids for each year.\n",
        "# Finally, find the difference between the two sets of customer_ids to get customers who exist in 2005 but not in 2006, and vice versa.\n",
        "customers_2005_df = rental_df.filter(year(\"rental_date\") == 2005) \\\n",
        "    .select(\"customer_id\").distinct()\n",
        "\n",
        "customers_2006_df = rental_df.filter(year(\"rental_date\") == 2006) \\\n",
        "    .select(\"customer_id\").distinct()\n",
        "\n",
        "# Customers in 2005 but not in 2006\n",
        "customers_2005_not_2006_df = customers_2005_df.subtract(customers_2006_df)\n",
        "\n",
        "# Show count rows for verification purposes\n",
        "print(\"Count of customers in 2005 but not in 2006:\", customers_2005_not_2006_df.count())\n",
        "\n",
        "# Customers in 2006 but not in 2005\n",
        "customers_2006_not_2005_df = customers_2006_df.subtract(customers_2005_df)\n",
        "\n",
        "# Show count for verification purposes\n",
        "print(\"Count of customers in 2006 but not in 2005:\", customers_2006_not_2005_df.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55IYkcfoFEqW",
        "outputId": "6ff58005-0528-4621-9b03-158c3ac14075"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of customers in 2005 but not in 2006: 441\n",
            "Count of customers in 2006 but not in 2005: 0\n"
          ]
        }
      ]
    }
  ]
}