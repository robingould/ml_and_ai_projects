{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Collaborative Filtering for Movie Recommendations"
      ],
      "metadata": {
        "id": "fZjH0F75sbOx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This example demonstrates Collaborative filtering using the Movielens dataset to recommend movies to users. The MovieLens ratings dataset lists the ratings given by a set of users to a set of movies. Our goal is to be able to predict ratings for movies a user has not yet watched. The movies with the highest predicted ratings can then be recommended to the user."
      ],
      "metadata": {
        "id": "_EF_lw8GskLI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The steps in the model are as follows:\n",
        "\n",
        "\n",
        "\n",
        "1.   Map user ID to a \"user vector\" via an embedding matrix\n",
        "2. Map movie ID to a \"movie vector\" via an embedding matrix\n",
        "3. Compute the dot product between the user vector and movie vector, to obtain the a match score between the user and the movie (predicted rating).\n",
        "4. Train the embeddings via gradient descent using all known user-movie pairs.\n",
        "\n"
      ],
      "metadata": {
        "id": "J4mazS9Nsd9N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4ukK2gmmsRtb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First, load the data and apply preprocessing"
      ],
      "metadata": {
        "id": "B12BznmbsnKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the actual data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        "# Use the ratings.csv file\n",
        "movielens_data_file_url = (\n",
        "    \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        ")\n",
        "movielens_zipped_file = keras.utils.get_file(\n",
        "    \"ml-latest-small.zip\", movielens_data_file_url, extract=False\n",
        ")\n",
        "keras_datasets_path = Path(movielens_zipped_file).parents[0]\n",
        "movielens_dir = keras_datasets_path / \"ml-latest-small\"\n",
        "\n",
        "# Only extract the data the first time the script is run.\n",
        "if not movielens_dir.exists():\n",
        "    with ZipFile(movielens_zipped_file, \"r\") as zip:\n",
        "        # Extract files\n",
        "        print(\"Extracting all the files now...\")\n",
        "        zip.extractall(path=keras_datasets_path)\n",
        "        print(\"Done!\")\n",
        "\n",
        "ratings_file = movielens_dir / \"ratings.csv\"\n",
        "df = pd.read_csv(ratings_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y9h6AsKsplU",
        "outputId": "9b9c9d4d-e34f-4a62-d3cc-6ece7edb6645"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "978202/978202 [==============================] - 0s 0us/step\n",
            "Extracting all the files now...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, need to perform some preprocessing to encode users and movies as integer indices.\n",
        "\n"
      ],
      "metadata": {
        "id": "70RmNGYHstr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_ids = df[\"userId\"].unique().tolist()\n",
        "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
        "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
        "movie_ids = df[\"movieId\"].unique().tolist()\n",
        "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
        "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
        "df[\"user\"] = df[\"userId\"].map(user2user_encoded)\n",
        "df[\"movie\"] = df[\"movieId\"].map(movie2movie_encoded)\n",
        "\n",
        "num_users = len(user2user_encoded)\n",
        "num_movies = len(movie_encoded2movie)\n",
        "df[\"rating\"] = df[\"rating\"].values.astype(np.float32)\n",
        "# min and max ratings will be used to normalize the ratings later\n",
        "min_rating = min(df[\"rating\"])\n",
        "max_rating = max(df[\"rating\"])\n",
        "\n",
        "print(\n",
        "    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n",
        "        num_users, num_movies, min_rating, max_rating\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzWiMAVKst_D",
        "outputId": "32e18c47-3738-4e56-b4e4-6f5508611a0d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users: 610, Number of Movies: 9724, Min rating: 0.5, Max rating: 5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare training and validation data"
      ],
      "metadata": {
        "id": "mklVmnK_s3s3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1, random_state=42)\n",
        "x = df[[\"user\", \"movie\"]].values\n",
        "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
        "y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
        "# Assuming training on 90% of the data and validating on 10%.\n",
        "train_indices = int(0.9 * df.shape[0])\n",
        "x_train, x_val, y_train, y_val = (\n",
        "    x[:train_indices],\n",
        "    x[train_indices:],\n",
        "    y[:train_indices],\n",
        "    y[train_indices:],\n",
        ")"
      ],
      "metadata": {
        "id": "4a3HOuSss4-a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the model"
      ],
      "metadata": {
        "id": "76cmbLe7s9Pk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We embed both users and movies in to 50-dimensional vectors.\n",
        "\n",
        "The model computes a match score between user and movie embeddings via a dot product, and adds a per-movie and per-user bias. The match score is scaled to the `[0, 1]` interval via a sigmoid (since our ratings are normalized to this range)."
      ],
      "metadata": {
        "id": "RE8sKLk4s7F4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 50\n",
        "\n",
        "\n",
        "class RecommenderNet(keras.Model):\n",
        "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
        "        super(RecommenderNet, self).__init__(**kwargs)\n",
        "        self.num_users = num_users\n",
        "        self.num_movies = num_movies\n",
        "        self.embedding_size = embedding_size\n",
        "        self.user_embedding = layers.Embedding(\n",
        "            num_users,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.user_bias = layers.Embedding(num_users, 1)\n",
        "        self.movie_embedding = layers.Embedding(\n",
        "            num_movies,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_vector = self.user_embedding(inputs[:, 0])\n",
        "        user_bias = self.user_bias(inputs[:, 0])\n",
        "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
        "        movie_bias = self.movie_bias(inputs[:, 1])\n",
        "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
        "        # Add all the components (including bias)\n",
        "        x = dot_user_movie + user_bias + movie_bias\n",
        "        # The sigmoid activation forces the rating to between 0 and 1\n",
        "        return tf.nn.sigmoid(x)\n",
        "\n",
        "\n",
        "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txddSQ63s_fO",
        "outputId": "4bf4efb7-261c-4827-ace5-ff4f546b7696"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model based on the data split"
      ],
      "metadata": {
        "id": "6SzgNh6TtH79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting early stopping condition to prevent overfitting"
      ],
      "metadata": {
        "id": "4VjtqxK7uIg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callback = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0,\n",
        "    patience=0,\n",
        "    verbose=0,\n",
        "    mode='auto'\n",
        ")"
      ],
      "metadata": {
        "id": "KwqqoNuhtjr6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    verbose=1,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-IaoPq2tHyG",
        "outputId": "50e3ee35-e4da-40d5-fa95-766efd85bc29"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1418/1418 [==============================] - 14s 10ms/step - loss: 0.6064 - val_loss: 0.6144\n",
            "Epoch 2/10\n",
            "1418/1418 [==============================] - 14s 10ms/step - loss: 0.6073 - val_loss: 0.6142\n",
            "Epoch 3/10\n",
            "1418/1418 [==============================] - 13s 9ms/step - loss: 0.6056 - val_loss: 0.6136\n",
            "Epoch 4/10\n",
            "1418/1418 [==============================] - 14s 10ms/step - loss: 0.6049 - val_loss: 0.6137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, we stop after 4 epochs as validation loss starts to rise."
      ],
      "metadata": {
        "id": "fl92-0xzurG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing other batch sizes"
      ],
      "metadata": {
        "id": "VEHJw3Z6umpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manually finding the loss of different batch sizes on the model"
      ],
      "metadata": {
        "id": "8KCbhrL3va_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        "    verbose=1,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3NCP7qOu5Ug",
        "outputId": "c510abf8-ca76-45e7-a489-c764a8d80d88"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2836/2836 [==============================] - 28s 10ms/step - loss: 0.5987 - val_loss: 0.6100\n",
            "Epoch 2/10\n",
            "2836/2836 [==============================] - 28s 10ms/step - loss: 0.5976 - val_loss: 0.6103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=128,\n",
        "    epochs=10,\n",
        "    verbose=1,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54pnwQR7vYdF",
        "outputId": "f46b0b31-1b16-4d10-b547-8889b2c0b20c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "709/709 [==============================] - 7s 10ms/step - loss: 0.6284 - val_loss: 0.6584\n",
            "Epoch 2/10\n",
            "709/709 [==============================] - 8s 12ms/step - loss: 0.6386 - val_loss: 0.6378\n",
            "Epoch 3/10\n",
            "709/709 [==============================] - 8s 11ms/step - loss: 0.6398 - val_loss: 0.6438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=256,\n",
        "    epochs=10,\n",
        "    verbose=1,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXlpiWtLvitR",
        "outputId": "df803976-5cb0-4545-ebb7-bd85e194c9d7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "355/355 [==============================] - 3s 9ms/step - loss: 0.6919 - val_loss: 0.6545\n",
            "Epoch 2/10\n",
            "355/355 [==============================] - 4s 12ms/step - loss: 0.6897 - val_loss: 0.6518\n",
            "Epoch 3/10\n",
            "355/355 [==============================] - 3s 9ms/step - loss: 0.7012 - val_loss: 0.6539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our best results were from lower batch sizes. As the batch size increased, both our validation loss and standard loss increased. In fact, with batch sizes with higher than 64, our loss increased showing our fit was getting worse on our data as we trained more."
      ],
      "metadata": {
        "id": "qqQJfdFMvt6p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manually testing different embedding sizes"
      ],
      "metadata": {
        "id": "SaPNmAunwPRr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing various embedding sizes effect on our best batch size model's loss"
      ],
      "metadata": {
        "id": "6n__Jb3Awmf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 100\n",
        "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wcBk4Z2wlZ9",
        "outputId": "988c722f-16ae-49c9-a43f-9fe8f3b8392e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        "    verbose=1,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igo6f5mgwOjL",
        "outputId": "faf0665f-1faf-4de4-9e16-88a7ac1d8b78"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2836/2836 [==============================] - 46s 16ms/step - loss: 0.6300 - val_loss: 0.6200\n",
            "Epoch 2/10\n",
            "2836/2836 [==============================] - 43s 15ms/step - loss: 0.6171 - val_loss: 0.6209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 150\n",
        "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1NHhjIKwzsl",
        "outputId": "1ee2139b-0e0f-4c65-e900-45903795b00b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        "    verbose=1,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5LujFk5w0wB",
        "outputId": "f0200f27-8efe-48b9-cac4-b1d620f2e4e4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2836/2836 [==============================] - 68s 23ms/step - loss: 0.6324 - val_loss: 0.6227\n",
            "Epoch 2/10\n",
            "2836/2836 [==============================] - 67s 24ms/step - loss: 0.6295 - val_loss: 0.6310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 200\n",
        "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HIgUtyhw2l3",
        "outputId": "a7ad0e58-f9f4-46a6-d21c-f089b714647f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        "    verbose=1,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKtcB53Pw30C",
        "outputId": "02c13efb-15ad-462e-dac8-8cd335dd830c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2836/2836 [==============================] - 86s 30ms/step - loss: 0.6335 - val_loss: 0.6241\n",
            "Epoch 2/10\n",
            "2836/2836 [==============================] - 84s 30ms/step - loss: 0.6466 - val_loss: 0.6438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the batch size of 32, higher embedding sizes after 50 seemed to increase the loss"
      ],
      "metadata": {
        "id": "4-SXDcmgwx-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show top 10 movie recommendations to a user"
      ],
      "metadata": {
        "id": "IAeigN0r9YJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_df = pd.read_csv(movielens_dir / \"movies.csv\")\n",
        "\n",
        "# Let us get a user and see the top recommendations.\n",
        "user_id = df.userId.sample(1).iloc[0]\n",
        "for user_id in df.userId:\n",
        "  movies_watched_by_user = df[df.userId == user_id]\n",
        "  movies_not_watched = movie_df[\n",
        "      ~movie_df[\"movieId\"].isin(movies_watched_by_user.movieId.values)\n",
        "  ][\"movieId\"]\n",
        "  movies_not_watched = list(\n",
        "      set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n",
        "  )\n",
        "  movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
        "  user_encoder = user2user_encoded.get(user_id)\n",
        "  user_movie_array = np.hstack(\n",
        "      ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n",
        "  )\n",
        "  ratings = model.predict(user_movie_array).flatten()\n",
        "  top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
        "  recommended_movie_ids = [\n",
        "      movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
        "  ]\n",
        "\n",
        "  print(\"Showing recommendations for user: {}\".format(user_id))\n",
        "  print(\"====\" * 9)\n",
        "  print(\"Movies with high ratings from user\")\n",
        "  print(\"----\" * 8)\n",
        "  top_movies_user = (\n",
        "      movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
        "      .head(5)\n",
        "      .movieId.values\n",
        "  )\n",
        "  movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n",
        "  for row in movie_df_rows.itertuples():\n",
        "      print(row.title, \":\", row.genres)\n",
        "\n",
        "  print(\"----\" * 8)\n",
        "  print(\"Top 10 movie recommendations\")\n",
        "  print(\"----\" * 8)\n",
        "  recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
        "  for row in recommended_movies.itertuples():\n",
        "      print(row.title, \":\", row.genres)"
      ],
      "metadata": {
        "id": "YaLH7u_c9XF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommendations_data = []\n",
        "\n",
        "def get_top_recommendations(user_id):\n",
        "    movies_watched_by_user = df[df.userId == user_id]\n",
        "    movies_not_watched = movie_df[~movie_df[\"movieId\"].isin(movies_watched_by_user.movieId.values)][\"movieId\"]\n",
        "    movies_not_watched = list(set(movies_not_watched).intersection(set(movie2movie_encoded.keys())))\n",
        "    movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
        "    user_encoder = user2user_encoded.get(user_id)\n",
        "    user_movie_array = np.hstack(([[user_encoder]] * len(movies_not_watched), movies_not_watched))\n",
        "    ratings = model.predict(user_movie_array).flatten()\n",
        "    top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
        "    recommended_movie_ids = [movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices]\n",
        "    return recommended_movie_ids\n",
        "\n",
        "for user_id in df.userId.unique():\n",
        "    top_movies_user = movies_watched_by_user.sort_values(by=\"rating\", ascending=False).head(5).movieId.values\n",
        "    movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n",
        "    for row in movie_df_rows.itertuples():\n",
        "        recommendations_data.append({'user_id': user_id, 'movie_title': row.title, 'movie_genre': row.genres})\n",
        "\n",
        "    recommended_movie_ids = get_top_recommendations(user_id)\n",
        "    recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
        "    for row in recommended_movies.itertuples():\n",
        "        recommendations_data.append({'user_id': user_id, 'movie_title': row.title, 'movie_genre': row.genres})\n",
        "\n",
        "recommendations_df = pd.DataFrame(recommendations_data)\n",
        "\n",
        "recommendations_df.to_excel(\"user_movie_recommendations.xlsx\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "My1PZJzdFdv8",
        "outputId": "0dffd91b-fd95-48c3-8401-3d45edcecbe4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300/300 [==============================] - 1s 2ms/step\n",
            "300/300 [==============================] - 1s 2ms/step\n",
            "299/299 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "302/302 [==============================] - 0s 2ms/step\n",
            "301/301 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "301/301 [==============================] - 0s 1ms/step\n",
            "301/301 [==============================] - 0s 1ms/step\n",
            "302/302 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "302/302 [==============================] - 1s 2ms/step\n",
            "300/300 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 1s 2ms/step\n",
            "302/302 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 1s 2ms/step\n",
            "301/301 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "301/301 [==============================] - 0s 2ms/step\n",
            "302/302 [==============================] - 0s 2ms/step\n",
            "298/298 [==============================] - 0s 2ms/step\n",
            "300/300 [==============================] - 1s 2ms/step\n",
            "302/302 [==============================] - 0s 1ms/step\n",
            "302/302 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "301/301 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "302/302 [==============================] - 1s 2ms/step\n",
            "300/300 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "301/301 [==============================] - 0s 2ms/step\n",
            "302/302 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "295/295 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "302/302 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "301/301 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 1s 2ms/step\n",
            "301/301 [==============================] - 1s 2ms/step\n",
            "302/302 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "300/300 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "299/299 [==============================] - 0s 1ms/step\n",
            "302/302 [==============================] - 0s 1ms/step\n",
            "301/301 [==============================] - 0s 2ms/step\n",
            "302/302 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "302/302 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 1s 2ms/step\n",
            "300/300 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "302/302 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "300/300 [==============================] - 0s 1ms/step\n",
            "302/302 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "302/302 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "302/302 [==============================] - 0s 1ms/step\n",
            "300/300 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "301/301 [==============================] - 1s 2ms/step\n",
            "301/301 [==============================] - 0s 2ms/step\n",
            "301/301 [==============================] - 0s 2ms/step\n",
            "300/300 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "302/302 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "301/301 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "297/297 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "299/299 [==============================] - 0s 2ms/step\n",
            "301/301 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "302/302 [==============================] - 0s 1ms/step\n",
            "301/301 [==============================] - 0s 2ms/step\n",
            "302/302 [==============================] - 0s 1ms/step\n",
            "302/302 [==============================] - 0s 2ms/step\n",
            "302/302 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "300/300 [==============================] - 1s 2ms/step\n",
            "298/298 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "301/301 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "302/302 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "298/298 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "301/301 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "301/301 [==============================] - 0s 2ms/step\n",
            "298/298 [==============================] - 0s 2ms/step\n",
            "297/297 [==============================] - 0s 2ms/step\n",
            "301/301 [==============================] - 0s 2ms/step\n",
            "302/302 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "300/300 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "302/302 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "301/301 [==============================] - 0s 2ms/step\n",
            "302/302 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "300/300 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "302/302 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "302/302 [==============================] - 0s 1ms/step\n",
            "301/301 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "301/301 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "302/302 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "302/302 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "302/302 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "300/300 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "302/302 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 1s 2ms/step\n",
            "300/300 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "302/302 [==============================] - 0s 1ms/step\n",
            "301/301 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "301/301 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 1s 3ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "302/302 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "302/302 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "302/302 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 1ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "303/303 [==============================] - 1s 3ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 1s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "304/304 [==============================] - 0s 2ms/step\n",
            "303/303 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    }
  ]
}